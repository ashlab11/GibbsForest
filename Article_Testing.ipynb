{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe want to create a series of graphs. \\n1. Compare the performance of the Dynaforest algorithm with the Random Forest algorithm.\\n2. Compare the performance of the Dynaforest algorithm with the XGBoost algorithm.\\n3. Compare time-complexity of the Dynaforest algorithm with the Random Forest algorithm.\\n4. Compare average tree bias of Dynaforest with Random Forest.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "from Dynaforest import Dynatree\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.datasets import make_friedman1, make_friedman2, make_friedman3\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import inspect\n",
    "\n",
    "\"\"\"\n",
    "We want to create a series of graphs. \n",
    "1. Compare the performance of the Dynaforest algorithm with the Random Forest algorithm.\n",
    "2. Compare the performance of the Dynaforest algorithm with the XGBoost algorithm.\n",
    "3. Compare time-complexity of the Dynaforest algorithm with the Random Forest algorithm.\n",
    "4. Compare average tree bias of Dynaforest with Random Forest.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Performance of Algorithms on Various Training Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_loss(model, dataset_creator, param_dict):\n",
    "    test_losses = []\n",
    "    for i in range(1):\n",
    "        X_train, y_train = dataset_creator(n_samples=200, noise=1)\n",
    "        X_test, y_test = dataset_creator(n_samples=1000, noise=1)\n",
    "        \n",
    "        grid = RandomizedSearchCV(model, param_dict, cv=2, n_iter=3, verbose = 2)\n",
    "        \n",
    "        grid.fit(X_train, y_train)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        test_loss = np.mean((y_pred - y_test) ** 2)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f\"iteration {i} loss: {np.mean(test_loss)}\")\n",
    "    return test_losses\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "This forest has a total of 842 splits\n",
      "This forest has a total of 30 trees\n",
      "[CV] END feature_subsampling_pct=0.2, max_depth=6, n_trees=30, window=10; total time=   6.7s\n",
      "This forest has a total of 854 splits\n",
      "This forest has a total of 30 trees\n",
      "[CV] END feature_subsampling_pct=0.2, max_depth=6, n_trees=30, window=10; total time=   6.9s\n",
      "This forest has a total of 1177 splits\n",
      "This forest has a total of 60 trees\n",
      "[CV] END feature_subsampling_pct=0.4, max_depth=5, n_trees=60, window=5; total time=   6.6s\n",
      "This forest has a total of 1301 splits\n",
      "This forest has a total of 60 trees\n",
      "[CV] END feature_subsampling_pct=0.4, max_depth=5, n_trees=60, window=5; total time=   7.8s\n",
      "This forest has a total of 1687 splits\n",
      "This forest has a total of 90 trees\n",
      "[CV] END feature_subsampling_pct=0.5, max_depth=5, n_trees=90, window=3; total time=   7.3s\n",
      "This forest has a total of 1773 splits\n",
      "This forest has a total of 90 trees\n",
      "[CV] END feature_subsampling_pct=0.5, max_depth=5, n_trees=90, window=3; total time=   8.0s\n",
      "This forest has a total of 2227 splits\n",
      "This forest has a total of 90 trees\n",
      "iteration 0 loss: 8.134547298549814\n",
      "XGBoost average loss:  8.134547298549814\n"
     ]
    }
   ],
   "source": [
    "# testing with xgboost\n",
    "\n",
    "param_dist = {\n",
    "    'n_trees': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'feature_subsampling_pct': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'window': [3, 5, 10]\n",
    "}\n",
    "\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "\n",
    "xgb_model = Dynatree()\n",
    "xgb_losses = get_average_loss(xgb_model, make_friedman1, param_dist)\n",
    "print(\"XGBoost average loss: \", np.mean(xgb_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_array = np.ma.masked_array([1, 2, -1, -2], mask = [False, False, True, False])\n",
    "unique_idx = np.unique(masked_array, return_index=True)[1]\n",
    "print(unique_idx)\n",
    "np.ma.argmin(masked_array[unique_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
